{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pattern recognition COVID-19 .ipynb",
      "provenance": [],
      "collapsed_sections": [
        "XI4kt6kxp9Sb",
        "5W5ciSKAamPA",
        "QsCSCRGgj50N",
        "G8scDQHDNjIZ",
        "5CtL3gNozqhQ",
        "gml4qd1rNyfW",
        "OGCz-h_tNmbn",
        "CJhl-AD05N6Y",
        "1G6QeGLFtwm6",
        "BIB2yq_F5egT",
        "xrf7oIF-5WPq",
        "AA9HHIBHVRO8",
        "avFD8Jl9T_Dq"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedhossam822/Chest_X-ray_Diagnosis/blob/main/Pattern_recognition_COVID_19_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYT9Bssq6IjT"
      },
      "source": [
        "# **Downloading dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "_S7MmTOteFEz",
        "outputId": "12e1a6d9-0bb6-4d84-eea5-7190703e9c1e"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9ecb4bfc-8eaf-44eb-8d37-8083ae95be9d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9ecb4bfc-8eaf-44eb-8d37-8083ae95be9d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"hosamtarek\",\"key\":\"e876952ca558c43f1aa900273ae407e6\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqotacfHHdv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eaa89a5-cb71-4df5-aa26-b3bea149beb0"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d tawsifurrahman/covid19-radiography-database\n",
        "from zipfile import ZipFile\n",
        "file_name = \"covid19-radiography-database.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading covid19-radiography-database.zip to /content\n",
            " 99% 1.13G/1.14G [00:09<00:00, 120MB/s] \n",
            "100% 1.14G/1.14G [00:09<00:00, 127MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrtHsnfb6RDV"
      },
      "source": [
        "# **Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKSCiBajSDWK"
      },
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim \n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from sklearn.metrics import f1_score,accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V6pF_YX6br_"
      },
      "source": [
        "# **Reading images**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI4kt6kxp9Sb"
      },
      "source": [
        "## Covid Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Al2OPRiIqee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05831275-f8c4-4132-e785-87f2d8c4c67c"
      },
      "source": [
        "img_matrix=[]\n",
        "# 60-20-20 ////////// 70-15-15\n",
        "covid_folder_path=\"/content/COVID-19 Radiography Database/COVID\"\n",
        "Normal_folder_path=\"/content/COVID-19 Radiography Database/NORMAL\"\n",
        "Viral_pneumonia_path=\"/content/COVID-19 Radiography Database/Viral Pneumonia\"\n",
        "\n",
        "covid_train=[]\n",
        "covid_validate=[]\n",
        "covid_test=[]\n",
        "\n",
        "i=1\n",
        "for file in os.listdir(covid_folder_path):\n",
        "     \n",
        "    if file.endswith(\".png\"):\n",
        "      img=cv2.imread(os.path.join(\"/content/COVID-19 Radiography Database/COVID\", file))\n",
        "      dim = (256, 256)\n",
        "      img=cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "      if i<=(60/100)*1200:\n",
        "        covid_train.append(img)\n",
        "        #covid_train.append(cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)) # rotate img then append it to train set\n",
        "        #covid_train.append(cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE))       \n",
        "        i+=1\n",
        "      elif i<=(80/100)*1200:\n",
        "        covid_validate.append(img)\n",
        "        i+=1\n",
        "      else:\n",
        "        covid_test.append(img)\n",
        "        i+=1\n",
        "\n",
        "covid_train=np.array(covid_train)\n",
        "covid_validate=np.array(covid_validate)\n",
        "covid_test=np.array(covid_test)\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W5ciSKAamPA"
      },
      "source": [
        "## Normal Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CImcNc9PacxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71b3df47-cea6-4f86-e35c-b9663d077cd9"
      },
      "source": [
        "Normal_train=[]\n",
        "Normal_validate=[]\n",
        "Normal_test=[]\n",
        "i=1\n",
        "for file in os.listdir(\"/content/COVID-19 Radiography Database/NORMAL\"):\n",
        "    if file.endswith(\".png\"):\n",
        "      img=cv2.imread(os.path.join(\"/content/COVID-19 Radiography Database/NORMAL\", file))\n",
        "      dim = (256, 256)\n",
        "      img=cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "      if i<(60/100)*1341:\n",
        "        Normal_train.append(img)\n",
        "        #Normal_train.append(cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE))\n",
        "        #Normal_train.append(cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
        "        i+=1\n",
        "      elif i<(80/100)*1341:\n",
        "        Normal_validate.append(img)\n",
        "        i+=1\n",
        "      else:\n",
        "        Normal_test.append(img)\n",
        "        i+=1\n",
        "Normal_train=np.array(Normal_train)\n",
        "Normal_validate=np.array(Normal_validate)\n",
        "Normal_test=np.array(Normal_test)\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQV8AR_1eFc9"
      },
      "source": [
        "## Viral Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMd5Eq92bIw3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee370da-a677-4b4e-b08b-4122633a1268"
      },
      "source": [
        "Viral_train=[]\n",
        "Viral_validate=[]\n",
        "Viral_test=[]\n",
        "i=1\n",
        "for file in os.listdir(\"/content/COVID-19 Radiography Database/Viral Pneumonia\"):\n",
        "    if file.endswith(\".png\"):\n",
        "      img=cv2.imread(os.path.join(\"/content/COVID-19 Radiography Database/Viral Pneumonia\", file))\n",
        "      dim = (256, 256)\n",
        "      img=cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "      if i<(60/100)*1346:\n",
        "        Viral_train.append(img)\n",
        "        #Viral_train.append(cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE))\n",
        "        #Viral_train.append(cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
        "        i+=1\n",
        "      elif i<(80/100)*1346:\n",
        "        Viral_validate.append(img)\n",
        "        i+=1\n",
        "      else:\n",
        "        Viral_test.append(img)\n",
        "        i+=1\n",
        "Viral_train=np.array(Viral_train)\n",
        "Viral_validate=np.array(Viral_validate)\n",
        "Viral_test=np.array(Viral_test)\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WagP5JV5NbES"
      },
      "source": [
        "# **Combining test data , validate , train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p2ws0o53jnX"
      },
      "source": [
        "training_data=[]\n",
        "validate_data=[]\n",
        "test_data=[]\n",
        "\n",
        "for i in covid_train :\n",
        "  training_data.append([i,0])\n",
        "for i in Normal_train:\n",
        "  training_data.append([i,1])\n",
        "for i in Viral_train:\n",
        "  training_data.append([i,2])\n",
        "\n",
        "for i in covid_validate :\n",
        "  validate_data.append([i,0])\n",
        "for i in Normal_validate:\n",
        "  validate_data.append([i,1])\n",
        "for i in Viral_validate:\n",
        "  validate_data.append([i,2])\n",
        "\n",
        "for i in covid_test :\n",
        "  test_data.append([i,0])\n",
        "for i in Normal_test:\n",
        "  test_data.append([i,1])\n",
        "for i in Viral_test:\n",
        "  test_data.append([i,2])\n",
        "\n",
        "np.random.shuffle(training_data)\n",
        "np.random.shuffle(validate_data)\n",
        "np.random.shuffle(test_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsCSCRGgj50N"
      },
      "source": [
        "#**Data Loaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZD9nShG4X8M"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(training_data, batch_size=100)\n",
        "validate_loader = torch.utils.data.DataLoader(validate_data, batch_size=100)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YPl_TzGfX_v"
      },
      "source": [
        "# **Fully connected neural network**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah4K3reLPmUr"
      },
      "source": [
        "## Few Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX35nZxgAfNZ"
      },
      "source": [
        "class FCNNFewLayers(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features=256*256, out_features=1024) \n",
        "        self.fc2 = nn.Linear(in_features=1024, out_features=50)\n",
        "        self.out = nn.Linear(in_features=50, out_features=3) \n",
        "    \n",
        "    def forward(self, t):\n",
        "        t = self.fc1(t)\n",
        "        t = F.relu(t)\n",
        "\n",
        "        t = self.fc2(t)\n",
        "        t = F.relu(t)\n",
        "        t = self.out(t)\n",
        "        return F.log_softmax(t)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8scDQHDNjIZ"
      },
      "source": [
        "## Many Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTRJRMI5fWwB"
      },
      "source": [
        "class FCNNManyLayers(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features=256*256, out_features=4096) \n",
        "        self.fc2 = nn.Linear(in_features=4096, out_features=1024)\n",
        "        self.fc3 = nn.Linear(in_features=1024, out_features=512)\n",
        "        self.fc4 = nn.Linear(in_features=512, out_features=256)\n",
        "        self.fc5 = nn.Linear(in_features=256, out_features=128)\n",
        "        self.fc6 = nn.Linear(in_features=128, out_features=64) \n",
        "        self.fc7 = nn.Linear(in_features=64, out_features=32)\n",
        "        self.fc8 = nn.Linear(in_features=32, out_features=16)\n",
        "        self.fc9 = nn.Linear(in_features=16, out_features=8)\n",
        "        self.out = nn.Linear(in_features=8, out_features=3) \n",
        "    \n",
        "    def forward(self, t):\n",
        "        t = self.fc1(t)\n",
        "        t = F.relu(t)\n",
        "\n",
        "        t = self.fc2(t)\n",
        "        t = F.relu(t)\n",
        "\n",
        "        t = self.fc3(t)\n",
        "        t = F.relu(t)\n",
        "\n",
        "        t = self.fc4(t)\n",
        "        t = F.relu(t)\n",
        "\n",
        "        t = self.fc5(t)\n",
        "        t = F.relu(t)\n",
        "\n",
        "        t = self.fc6(t)\n",
        "        t = F.relu(t)\n",
        "\n",
        "        t = self.fc7(t)\n",
        "        t = F.relu(t)\n",
        "\n",
        "        t = self.fc8(t)\n",
        "        t = F.relu(t)\n",
        "\n",
        "        t = self.fc9(t)\n",
        "        t = F.relu(t)\n",
        "\n",
        "        t = self.out(t)\n",
        "        return F.log_softmax(t)\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CtL3gNozqhQ"
      },
      "source": [
        "# **CNN**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gml4qd1rNyfW"
      },
      "source": [
        "## Few Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y-dgxsOqsj6"
      },
      "source": [
        "class CNNFewLayers(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3,padding=1) \n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3,padding=1)\n",
        "\n",
        "        #Output of Thepool2d layer is[100,12,64,64]\n",
        "        self.fc1 = nn.Linear(in_features=12 * 64 * 64, out_features=12*3) \n",
        "        self.fc2 = nn.Linear(in_features=12*3, out_features=6*3)\n",
        "        self.out = nn.Linear(in_features=6*3, out_features=3) \n",
        "    \n",
        "    def forward(self, t):\n",
        "        t = self.conv1(t)\n",
        "        t = F.relu(t)\n",
        "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "        t = self.conv2(t)\n",
        "        t = F.relu(t)\n",
        "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "        #print(\"tensor shape:\",t.shape)\n",
        "        #Output of Thepool2d layer is[100,12,64,64]\n",
        "        t = t.reshape(-1, 12 * 64 * 64)\n",
        "        #(100,12*64*64)\n",
        "        t = self.fc1(t)\n",
        "        t = F.relu(t)\n",
        "\n",
        "        t = self.fc2(t)\n",
        "        t = F.relu(t)\n",
        "\n",
        "        t = self.out(t)\n",
        "        return t\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGCz-h_tNmbn"
      },
      "source": [
        "## Many Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiDGcFz-NxPJ"
      },
      "source": [
        "class CNNManyLayers(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3,padding=1) \n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3,padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3,padding=1)\n",
        "        \n",
        "        #Output of Thepool2d layer is[100,24,32,32]\n",
        "        self.fc1 = nn.Linear(in_features=24 * 32 * 32, out_features=24*3) \n",
        "        self.fc2 = nn.Linear(in_features=24*3, out_features=12*3)\n",
        "        self.fc3 = nn.Linear(in_features=12*3, out_features=6*3)\n",
        "        self.out = nn.Linear(in_features=6*3, out_features=3)\n",
        "    \n",
        "    def forward(self, t):\n",
        "        t = self.conv1(t)\n",
        "        t = F.relu(t)\n",
        "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "        t = self.conv2(t)\n",
        "        t = F.relu(t)\n",
        "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "        t = self.conv3(t)\n",
        "        t = F.relu(t)\n",
        "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "        #Output of Thepool2d layer is[64,24,32,32]\n",
        "        t = t.reshape(-1, 24 * 32 * 32)\n",
        "        t = self.fc1(t)\n",
        "        t = F.relu(t)\n",
        "\n",
        "        t = self.fc2(t)\n",
        "        t = F.relu(t)\n",
        "\n",
        "        t = self.fc3(t)\n",
        "        t = F.relu(t)\n",
        "\n",
        "        t = self.out(t)\n",
        "        return t\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yJqoV2-9QpW"
      },
      "source": [
        "# **ResNet18**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJhl-AD05N6Y"
      },
      "source": [
        "##Pretrained\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woQkEPCIt2TS"
      },
      "source": [
        "resnet18Pretrained =torchvision.models.resnet18(pretrained=True)\n",
        "resnet18Pretrained.fc=torch.nn.Linear(in_features=512, out_features=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDnM69fs5CJf"
      },
      "source": [
        "##Untrained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yekMGJNA9Vhv"
      },
      "source": [
        "resnet18 =torchvision.models.resnet18(pretrained=False)\n",
        "resnet18.fc=torch.nn.Linear(in_features=512, out_features=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G6QeGLFtwm6"
      },
      "source": [
        "# **ResNet50**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIB2yq_F5egT"
      },
      "source": [
        "##Pretrained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wexym92t2yH"
      },
      "source": [
        "resnet50Pretrained =torchvision.models.resnet50(pretrained=True)\n",
        "resnet50Pretrained.fc=torch.nn.Linear(in_features=2048, out_features=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrf7oIF-5WPq"
      },
      "source": [
        "##Untrained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0mUFGpR-V7k"
      },
      "source": [
        "resnet50 =torchvision.models.resnet50(pretrained=False)\n",
        "resnet50.fc=torch.nn.Linear(in_features=2048, out_features=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw5KQ4etJlVA"
      },
      "source": [
        "# **Trainning Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3T9jD0hJr_F"
      },
      "source": [
        "def Train(ModelType,optimizer):\n",
        "  preds_list=[]\n",
        "  label_list=[]\n",
        "  total_loss = 0\n",
        "  total_correct = 0\n",
        "  for batch in train_loader: \n",
        "      images, labels = batch \n",
        "      #reshape from(100,256,256,3) to (100,3,256,256)\n",
        "      images=images.reshape(len(images),3,256,256)\n",
        "      images=images.float()\n",
        "      #Fully connected\n",
        "      if(ModelType.__class__.__name__==\"FCNNFewLayers\" or ModelType.__class__.__name__==\"FCNNManyLayers\"):\n",
        "        images=torchvision.transforms.functional.rgb_to_grayscale(images,1)\n",
        "        images = images.view(-1, 256*256) #Change shape from (100,1,256,256)->(100,256*256)\n",
        "      \n",
        "      preds = ModelType(images)\n",
        "\n",
        "      for i in range(len(preds)):\n",
        "        preds_list.append(preds.argmax(dim=1)[i].item())\n",
        "        label_list.append(labels[i].item())\n",
        "\n",
        "      loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward() # Calculate Gradients\n",
        "      optimizer.step() # Update Weights\n",
        "      total_loss += loss.item()\n",
        "  return total_loss,accuracy_score(label_list, preds_list),f1_score(label_list, preds_list, average=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9HHIBHVRO8"
      },
      "source": [
        "# **Validation Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-FnHOedVc0m"
      },
      "source": [
        "def Validate(ModelType):\n",
        "  preds_list=[]\n",
        "  label_list=[]\n",
        "  total_loss = 0\n",
        "  total_correct = 0\n",
        "  for batch in validate_loader: \n",
        "      images, labels = batch \n",
        "      images=images.reshape(len(images),3,256,256)\n",
        "      images=images.float()\n",
        "\n",
        "      #Fully connected\n",
        "      if(ModelType.__class__.__name__==\"FCNNFewLayers\" or ModelType.__class__.__name__==\"FCNNManyLayers\"):\n",
        "        images=torchvision.transforms.functional.rgb_to_grayscale(images,1)\n",
        "        images = images.view(-1, 256*256)\n",
        "      \n",
        "      preds = ModelType(images)\n",
        "\n",
        "      for i in range(len(preds)):\n",
        "        preds_list.append(preds.argmax(dim=1)[i].item())\n",
        "        label_list.append(labels[i].item())\n",
        "\n",
        "      loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
        "      total_loss += loss.item()\n",
        "      total_correct =total_correct+preds.argmax(dim=1).eq(labels).sum()\n",
        "  return total_loss,accuracy_score(label_list, preds_list),f1_score(label_list, preds_list, average=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avFD8Jl9T_Dq"
      },
      "source": [
        "# **Test Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xNQG2hbULdo"
      },
      "source": [
        "def Test(ModelType):\n",
        "  preds_list=[]\n",
        "  label_list=[]\n",
        "  total_loss = 0\n",
        "  total_correct = 0\n",
        "  for batch in test_loader: \n",
        "      images, labels = batch \n",
        "      images=images.reshape(len(images),3,256,256)\n",
        "      images=images.float()\n",
        "\n",
        "      #Fully connected\n",
        "      if(ModelType.__class__.__name__==\"FCNNFewLayers\" or ModelType.__class__.__name__==\"FCNNManyLayers\"):\n",
        "        images=torchvision.transforms.functional.rgb_to_grayscale(images,1)\n",
        "        images = images.view(-1, 256*256)\n",
        "      \n",
        "      preds = ModelType(images)\n",
        "\n",
        "      for i in range(len(preds)):\n",
        "        preds_list.append(preds.argmax(dim=1)[i].item())\n",
        "        label_list.append(labels[i].item())\n",
        "\n",
        "      loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
        "      total_loss += loss.item()\n",
        "  return total_loss,accuracy_score(label_list, preds_list),f1_score(label_list, preds_list, average=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iI-767OHMyK"
      },
      "source": [
        "# Dataloader for resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA_FWvfRHLsK"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(training_data, batch_size=64)\n",
        "validate_loader = torch.utils.data.DataLoader(validate_data, batch_size=64)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuqekMN0ZG9h"
      },
      "source": [
        "# **Accurcy and f1 score report**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_fhZsjp24UA"
      },
      "source": [
        "def printResults(loss,accurcy,f1score):\n",
        "  print(\" loss: {:.2f} \".format(loss), end =\"\")\n",
        "  print(\" accurcy: {:.2f}% \".format(accurcy*100), end =\"\")\n",
        "  print(\" F1 of class 0: {:.2f}%  F1 of class 1: {:.2f}%  F1 of class 2: {:.2f}%\".format( f1score[0]*100, f1score[1]*100, f1score[2]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1nQQ5Vr1lOn"
      },
      "source": [
        "## Fully connected few"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVTSDZRC1ZVA",
        "outputId": "78317a06-56a7-4c97-fa24-a673bec78d7e"
      },
      "source": [
        "FCNNFnetwork=FCNNFewLayers()\n",
        "optimizer = optim.Adam(FCNNFnetwork.parameters(), lr=0.001)\n",
        "print(\"Trainning Phase :\")\n",
        "for epoch in range(10):\n",
        "  loss,accurcy,f1score=Train(FCNNFnetwork,optimizer)\n",
        "  print(\"epoch \",epoch,\" : \")\n",
        "  printResults(loss,accurcy,f1score)\n",
        "  \n",
        "print(\"Validation Phase :\")\n",
        "loss,accurcy,f1score=Validate(FCNNFnetwork)\n",
        "printResults(loss,accurcy,f1score)\n",
        "\n",
        "print(\"Test Phase :\")\n",
        "loss,accurcy,f1score=Test(FCNNFnetwork)\n",
        "printResults(loss,accurcy,f1score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainning Phase :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch  0  : \n",
            " loss: 23258.37  accurcy: 38.52%  F1 of class 0: 44.34%  F1 of class 1: 34.50%  F1 of class 2: 36.67%\n",
            "epoch  1  : \n",
            " loss: 614.41  accurcy: 68.55%  F1 of class 0: 85.85%  F1 of class 1: 58.42%  F1 of class 2: 62.86%\n",
            "epoch  2  : \n",
            " loss: 352.48  accurcy: 75.55%  F1 of class 0: 91.23%  F1 of class 1: 68.39%  F1 of class 2: 68.74%\n",
            "epoch  3  : \n",
            " loss: 555.91  accurcy: 70.01%  F1 of class 0: 87.32%  F1 of class 1: 62.10%  F1 of class 2: 62.41%\n",
            "epoch  4  : \n",
            " loss: 618.05  accurcy: 71.51%  F1 of class 0: 81.82%  F1 of class 1: 66.62%  F1 of class 2: 66.91%\n",
            "epoch  5  : \n",
            " loss: 480.35  accurcy: 75.80%  F1 of class 0: 87.94%  F1 of class 1: 71.63%  F1 of class 2: 69.29%\n",
            "epoch  6  : \n",
            " loss: 315.86  accurcy: 79.11%  F1 of class 0: 91.63%  F1 of class 1: 73.72%  F1 of class 2: 73.37%\n",
            "epoch  7  : \n",
            " loss: 441.58  accurcy: 75.63%  F1 of class 0: 87.22%  F1 of class 1: 72.06%  F1 of class 2: 68.99%\n",
            "epoch  8  : \n",
            " loss: 465.12  accurcy: 76.58%  F1 of class 0: 85.81%  F1 of class 1: 72.69%  F1 of class 2: 72.12%\n",
            "epoch  9  : \n",
            " loss: 257.44  accurcy: 82.75%  F1 of class 0: 92.61%  F1 of class 1: 79.16%  F1 of class 2: 77.60%\n",
            "Validation Phase :\n",
            " loss: 54.93  accurcy: 87.13%  F1 of class 0: 93.56%  F1 of class 1: 86.26%  F1 of class 2: 82.26%\n",
            "Test Phase :\n",
            " loss: 58.20  accurcy: 85.73%  F1 of class 0: 93.56%  F1 of class 1: 84.28%  F1 of class 2: 79.84%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE_63jZD5Twd"
      },
      "source": [
        "## Fully connected Many"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsdk36vU5dzu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38bfca1c-2f7c-4618-b5ed-dc975c29a101"
      },
      "source": [
        "FCNNMnetwork=FCNNManyLayers()\n",
        "optimizer = optim.Adam(FCNNMnetwork.parameters(), lr=0.001)\n",
        "print(\"Trainning Phase :\")\n",
        "for epoch in range(10):\n",
        "  loss,accurcy,f1score=Train(FCNNMnetwork,optimizer)\n",
        "  print(\"epoch \",epoch,\" : \")\n",
        "  printResults(loss,accurcy,f1score)\n",
        "  \n",
        "print(\"Validation Phase :\")\n",
        "loss,accurcy,f1score=Validate(FCNNMnetwork)\n",
        "printResults(loss,accurcy,f1score)\n",
        "\n",
        "print(\"Test Phase :\")\n",
        "loss,accurcy,f1score=Test(FCNNMnetwork)\n",
        "printResults(loss,accurcy,f1score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainning Phase :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch  0  : \n",
            " loss: 144.38  accurcy: 33.42%  F1 of class 0: 32.59%  F1 of class 1: 27.73%  F1 of class 2: 38.15%\n",
            "epoch  1  : \n",
            " loss: 27.46  accurcy: 35.86%  F1 of class 0: 37.81%  F1 of class 1: 38.62%  F1 of class 2: 30.23%\n",
            "epoch  2  : \n",
            " loss: 19.64  accurcy: 55.98%  F1 of class 0: 77.14%  F1 of class 1: 49.03%  F1 of class 2: 38.36%\n",
            "epoch  3  : \n",
            " loss: 15.91  accurcy: 62.63%  F1 of class 0: 90.38%  F1 of class 1: 50.48%  F1 of class 2: 49.60%\n",
            "epoch  4  : \n",
            " loss: 15.42  accurcy: 65.08%  F1 of class 0: 90.64%  F1 of class 1: 54.34%  F1 of class 2: 52.93%\n",
            "epoch  5  : \n",
            " loss: 14.83  accurcy: 66.92%  F1 of class 0: 90.62%  F1 of class 1: 59.35%  F1 of class 2: 52.96%\n",
            "epoch  6  : \n",
            " loss: 14.32  accurcy: 69.67%  F1 of class 0: 89.96%  F1 of class 1: 64.83%  F1 of class 2: 55.75%\n",
            "epoch  7  : \n",
            " loss: 13.65  accurcy: 72.84%  F1 of class 0: 90.79%  F1 of class 1: 67.05%  F1 of class 2: 62.77%\n",
            "epoch  8  : \n",
            " loss: 12.24  accurcy: 77.26%  F1 of class 0: 91.54%  F1 of class 1: 72.96%  F1 of class 2: 68.93%\n",
            "epoch  9  : \n",
            " loss: 10.21  accurcy: 82.50%  F1 of class 0: 92.42%  F1 of class 1: 79.14%  F1 of class 2: 77.17%\n",
            "Validation Phase :\n",
            " loss: 3.95  accurcy: 82.11%  F1 of class 0: 89.71%  F1 of class 1: 81.82%  F1 of class 2: 74.34%\n",
            "Test Phase :\n",
            " loss: 3.67  accurcy: 82.39%  F1 of class 0: 89.86%  F1 of class 1: 81.95%  F1 of class 2: 75.11%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpG3f5cA52IM"
      },
      "source": [
        "## CNN Few"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiTg1lQl58Zp",
        "outputId": "897efb45-f285-42f4-ccc4-e23acbab0480"
      },
      "source": [
        "CNNFnetwork=CNNFewLayers()\n",
        "optimizer = optim.Adamax(CNNFnetwork.parameters(), lr=0.01)\n",
        "print(\"Trainning Phase :\")\n",
        "for epoch in range(10):\n",
        "  loss,accurcy,f1score=Train(CNNFnetwork,optimizer)\n",
        "  print(\"epoch\",epoch,\": \")\n",
        "  printResults(loss,accurcy,f1score)\n",
        "  \n",
        "print(\"Validation Phase :\")\n",
        "loss,accurcy,f1score=Validate(CNNFnetwork)\n",
        "printResults(loss,accurcy,f1score)\n",
        "\n",
        "print(\"Test Phase :\")\n",
        "loss,accurcy,f1score=Test(CNNFnetwork)\n",
        "printResults(loss,accurcy,f1score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainning Phase :\n",
            "epoch 0 : \n",
            " loss: 4654.41  accurcy: 50.19%  F1 of class 0: 63.31%  F1 of class 1: 56.47%  F1 of class 2: 14.54%\n",
            "epoch 1 : \n",
            " loss: 17.68  accurcy: 64.52%  F1 of class 0: 86.58%  F1 of class 1: 63.98%  F1 of class 2: 37.27%\n",
            "epoch 2 : \n",
            " loss: 10.99  accurcy: 80.05%  F1 of class 0: 92.18%  F1 of class 1: 75.27%  F1 of class 2: 74.11%\n",
            "epoch 3 : \n",
            " loss: 9.04  accurcy: 85.59%  F1 of class 0: 93.66%  F1 of class 1: 82.96%  F1 of class 2: 81.13%\n",
            "epoch 4 : \n",
            " loss: 8.87  accurcy: 86.23%  F1 of class 0: 93.08%  F1 of class 1: 84.37%  F1 of class 2: 82.11%\n",
            "epoch 5 : \n",
            " loss: 8.38  accurcy: 86.23%  F1 of class 0: 94.31%  F1 of class 1: 83.46%  F1 of class 2: 81.91%\n",
            "epoch 6 : \n",
            " loss: 7.58  accurcy: 87.95%  F1 of class 0: 94.50%  F1 of class 1: 85.86%  F1 of class 2: 84.19%\n",
            "epoch 7 : \n",
            " loss: 6.73  accurcy: 88.55%  F1 of class 0: 95.40%  F1 of class 1: 86.45%  F1 of class 2: 84.54%\n",
            "epoch 8 : \n",
            " loss: 6.74  accurcy: 88.67%  F1 of class 0: 95.13%  F1 of class 1: 86.97%  F1 of class 2: 84.63%\n",
            "epoch 9 : \n",
            " loss: 6.36  accurcy: 89.36%  F1 of class 0: 95.45%  F1 of class 1: 87.83%  F1 of class 2: 85.52%\n",
            "Validation Phase :\n",
            " loss: 3.26  accurcy: 86.62%  F1 of class 0: 92.98%  F1 of class 1: 84.80%  F1 of class 2: 82.68%\n",
            "Test Phase :\n",
            " loss: 2.37  accurcy: 87.79%  F1 of class 0: 93.85%  F1 of class 1: 85.00%  F1 of class 2: 85.04%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv_CJF-Q6Jvv"
      },
      "source": [
        "## CNN Many"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svXv8xrR6NBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e98290cd-5c4c-47e4-d3b3-3e6619286cdd"
      },
      "source": [
        "CNNMnetwork=CNNManyLayers()\n",
        "optimizer = optim.Adamax(CNNMnetwork.parameters(), lr=0.01)\n",
        "print(\"Trainning Phase :\")\n",
        "for epoch in range(10):\n",
        "  loss,accurcy,f1score=Train(CNNMnetwork,optimizer)\n",
        "  print(\"epoch \",epoch,\" : \")\n",
        "  printResults(loss,accurcy,f1score)\n",
        "  \n",
        "print(\"Validation Phase :\")\n",
        "loss,accurcy,f1score=Validate(CNNMnetwork)\n",
        "printResults(loss,accurcy,f1score)\n",
        "\n",
        "print(\"Test Phase :\")\n",
        "loss,accurcy,f1score=Test(CNNMnetwork)\n",
        "printResults(loss,accurcy,f1score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainning Phase :\n",
            "epoch  0  : \n",
            " loss: 358.45  accurcy: 44.23%  F1 of class 0: 54.13%  F1 of class 1: 42.99%  F1 of class 2: 32.11%\n",
            "epoch  1  : \n",
            " loss: 13.19  accurcy: 74.43%  F1 of class 0: 88.32%  F1 of class 1: 73.03%  F1 of class 2: 62.26%\n",
            "epoch  2  : \n",
            " loss: 8.94  accurcy: 84.81%  F1 of class 0: 91.96%  F1 of class 1: 83.20%  F1 of class 2: 79.95%\n",
            "epoch  3  : \n",
            " loss: 7.30  accurcy: 87.69%  F1 of class 0: 92.12%  F1 of class 1: 87.21%  F1 of class 2: 84.15%\n",
            "epoch  4  : \n",
            " loss: 6.01  accurcy: 90.00%  F1 of class 0: 92.91%  F1 of class 1: 90.53%  F1 of class 2: 86.83%\n",
            "epoch  5  : \n",
            " loss: 4.88  accurcy: 92.36%  F1 of class 0: 94.13%  F1 of class 1: 93.34%  F1 of class 2: 89.75%\n",
            "epoch  6  : \n",
            " loss: 4.24  accurcy: 93.22%  F1 of class 0: 95.10%  F1 of class 1: 93.72%  F1 of class 2: 91.00%\n",
            "epoch  7  : \n",
            " loss: 3.57  accurcy: 94.17%  F1 of class 0: 96.11%  F1 of class 1: 93.99%  F1 of class 2: 92.59%\n",
            "epoch  8  : \n",
            " loss: 3.47  accurcy: 94.59%  F1 of class 0: 96.89%  F1 of class 1: 94.22%  F1 of class 2: 92.89%\n",
            "epoch  9  : \n",
            " loss: 3.81  accurcy: 93.78%  F1 of class 0: 95.71%  F1 of class 1: 94.02%  F1 of class 2: 91.78%\n",
            "Validation Phase :\n",
            " loss: 2.72  accurcy: 89.70%  F1 of class 0: 93.80%  F1 of class 1: 88.28%  F1 of class 2: 87.46%\n",
            "Test Phase :\n",
            " loss: 2.38  accurcy: 89.85%  F1 of class 0: 93.89%  F1 of class 1: 87.62%  F1 of class 2: 88.46%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eGDuXWS_U8N"
      },
      "source": [
        "## Resnet-18 Pretrained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv6_YEUB_juE"
      },
      "source": [
        "optimizer=optim.Adamax(resnet18Pretrained.parameters(), lr=0.01)\n",
        "\n",
        "resnet18Pretrained.train()\n",
        "print(\"Trainning Phase :\")\n",
        "for epoch in range(5):\n",
        "  loss,accurcy,f1score=Train(resnet18Pretrained,optimizer)\n",
        "  print(\"epoch \",epoch,\" : \")\n",
        "  printResults(loss,accurcy,f1score)\n",
        "\n",
        "resnet18Pretrained.eval()\n",
        "print(\"Validation Phase :\")\n",
        "loss,accurcy,f1score=Validate(resnet18Pretrained)\n",
        "printResults(loss,accurcy,f1score)\n",
        "\n",
        "print(\"Test Phase :\")\n",
        "loss,accurcy,f1score=Test(resnet18Pretrained)\n",
        "printResults(loss,accurcy,f1score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "592q7metCb69"
      },
      "source": [
        "## Resnet-18 Untrained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5oPNtZ9GwT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0a26659-3353-4485-c24f-bb7b093e1dcc"
      },
      "source": [
        "optimizer=optim.Adamax(resnet18.parameters(), lr=0.01)\n",
        "\n",
        "resnet18.train()\n",
        "print(\"Trainning Phase :\")\n",
        "for epoch in range(5):\n",
        "  loss,accurcy,f1score=Train(resnet18,optimizer)\n",
        "  print(\"epoch \",epoch,\" : \")\n",
        "  printResults(loss,accurcy,f1score)\n",
        "\n",
        "resnet18.eval()\n",
        "print(\"Validation Phase :\")\n",
        "loss,accurcy,f1score=Validate(resnet18)\n",
        "printResults(loss,accurcy,f1score)\n",
        "\n",
        "print(\"Test Phase :\")\n",
        "loss,accurcy,f1score=Test(resnet18)\n",
        "printResults(loss,accurcy,f1score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainning Phase :\n",
            "epoch  0  : \n",
            " loss: 36.99  accurcy: 62.85%  F1 of class 0: 76.42%  F1 of class 1: 61.94%  F1 of class 2: 50.74%\n",
            "epoch  1  : \n",
            " loss: 18.95  accurcy: 79.24%  F1 of class 0: 89.52%  F1 of class 1: 78.10%  F1 of class 2: 70.01%\n",
            "epoch  2  : \n",
            " loss: 15.57  accurcy: 84.21%  F1 of class 0: 91.44%  F1 of class 1: 82.43%  F1 of class 2: 79.47%\n",
            "epoch  3  : \n",
            " loss: 12.13  accurcy: 88.50%  F1 of class 0: 92.88%  F1 of class 1: 87.26%  F1 of class 2: 85.82%\n",
            "epoch  4  : \n",
            " loss: 10.94  accurcy: 90.09%  F1 of class 0: 93.25%  F1 of class 1: 89.89%  F1 of class 2: 87.49%\n",
            "Validation Phase :\n",
            " loss: 4.67  accurcy: 87.00%  F1 of class 0: 90.55%  F1 of class 1: 86.86%  F1 of class 2: 83.69%\n",
            "Test Phase :\n",
            " loss: 4.87  accurcy: 85.73%  F1 of class 0: 90.87%  F1 of class 1: 86.56%  F1 of class 2: 79.76%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l040IZ_MGxAR"
      },
      "source": [
        "## Resnet-50 Pretrained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHdaZACEG3g8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffd255fa-9962-414b-bbc6-49a1882786df"
      },
      "source": [
        "optimizer=optim.Adamax(resnet50Pretrained.parameters(), lr=0.01)\n",
        "resnet50Pretrained.train()\n",
        "print(\"Trainning Phase :\")\n",
        "for epoch in range(5):\n",
        "  loss,accurcy,f1score=Train(resnet50Pretrained,optimizer)\n",
        "  print(\"epoch \",epoch,\" : \")\n",
        "  printResults(loss,accurcy,f1score)\n",
        "\n",
        "resnet50Pretrained.eval()\n",
        "print(\"Validation Phase :\")\n",
        "loss,accurcy,f1score=Validate(resnet50Pretrained)\n",
        "printResults(loss,accurcy,f1score)\n",
        "\n",
        "print(\"Test Phase :\")\n",
        "loss,accurcy,f1score=Test(resnet50Pretrained)\n",
        "printResults(loss,accurcy,f1score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainning Phase :\n",
            "epoch  0  : \n",
            " loss: 35.25  accurcy: 57.06%  F1 of class 0: 76.21%  F1 of class 1: 54.54%  F1 of class 2: 43.34%\n",
            "epoch  1  : \n",
            " loss: 23.62  accurcy: 73.36%  F1 of class 0: 88.90%  F1 of class 1: 67.28%  F1 of class 2: 65.24%\n",
            "epoch  2  : \n",
            " loss: 16.08  accurcy: 83.83%  F1 of class 0: 92.04%  F1 of class 1: 80.93%  F1 of class 2: 79.30%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc5Iz9sIG3ww"
      },
      "source": [
        "## Resnet-50 Untrained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie3Q5tkQG9XG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ca2be0f-9696-467c-ef98-1cb02e7b7de2"
      },
      "source": [
        "optimizer=optim.Adamax(resnet50.parameters(), lr=0.01)\n",
        "resnet50.train()\n",
        "print(\"Trainning Phase :\")\n",
        "for epoch in range(5):\n",
        "  loss,accurcy,f1score=Train(resnet50,optimizer)\n",
        "  print(\"epoch \",epoch,\" : \")\n",
        "  printResults(loss,accurcy,f1score)\n",
        "\n",
        "resnet50.eval()\n",
        "print(\"Validation Phase :\")\n",
        "loss,accurcy,f1score=Validate(resnet50)\n",
        "printResults(loss,accurcy,f1score)\n",
        "\n",
        "print(\"Test Phase :\")\n",
        "loss,accurcy,f1score=Test(resnet50)\n",
        "printResults(loss,accurcy,f1score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainning Phase :\n",
            "epoch  0  : \n",
            " loss: 48.12  accurcy: 59.93%  F1 of class 0: 79.94%  F1 of class 1: 47.22%  F1 of class 2: 54.01%\n",
            "epoch  1  : \n",
            " loss: 22.40  accurcy: 73.57%  F1 of class 0: 91.36%  F1 of class 1: 66.75%  F1 of class 2: 64.06%\n",
            "epoch  2  : \n",
            " loss: 16.79  accurcy: 81.81%  F1 of class 0: 91.77%  F1 of class 1: 78.11%  F1 of class 2: 76.40%\n",
            "epoch  3  : \n",
            " loss: 13.80  accurcy: 86.14%  F1 of class 0: 93.17%  F1 of class 1: 83.32%  F1 of class 2: 82.61%\n",
            "epoch  4  : \n",
            " loss: 11.89  accurcy: 88.46%  F1 of class 0: 94.18%  F1 of class 1: 86.08%  F1 of class 2: 85.61%\n",
            "Validation Phase :\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}